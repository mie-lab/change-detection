{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "import glob, sys, os\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import config\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"trackintel\"))\n",
    "from trackintel.analysis.tracking_quality import temporal_tracking_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User number: 139 139\n",
      "starting merge (259887, 12) (245689, 9)\n",
      "finished merge (505576, 17)\n",
      "**************************************************\n",
      "139 139 139\n"
     ]
    }
   ],
   "source": [
    "def get_stps():\n",
    "    stps = pd.read_csv(os.path.join(config['proc'], 'stps_act_user_50.csv'))\n",
    "    \n",
    "    stps.rename(columns={\"user_id\": \"userid\", \"started_at\": \"startt\", \"finished_at\": \"endt\"},inplace=True)\n",
    "\n",
    "    stps['startt'] = pd.to_datetime(stps['startt']).dt.tz_localize(None)\n",
    "    stps['endt'] = pd.to_datetime(stps['endt']).dt.tz_localize(None)\n",
    "    return stps\n",
    "\n",
    "def get_trips():\n",
    "    trips = pd.read_csv(os.path.join(config['proc'], 'trips.csv'))\n",
    "\n",
    "    trips.rename(columns={\"user_id\": \"userid\", \"started_at\": \"startt\", \"finished_at\": \"endt\"}, inplace=True)\n",
    "\n",
    "    trips['startt'] = pd.to_datetime(trips['startt']).dt.tz_localize(None)\n",
    "    trips['endt'] = pd.to_datetime(trips['endt']).dt.tz_localize(None)\n",
    "    return trips\n",
    "\n",
    "def _preprocess(df):\n",
    "    df.rename(\n",
    "        columns={\"userid\": \"user_id\", \"startt\": \"started_at\", \"endt\": \"finished_at\", \"dur_s\": \"duration\"}, inplace=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def _get_all_trace(stps, trips):\n",
    "\n",
    "    stps = _preprocess(stps)\n",
    "    trips = _preprocess(trips)\n",
    "    print(\"User number:\", len(stps[\"user_id\"].unique()), len(trips[\"user_id\"].unique()))\n",
    "\n",
    "    # merge trips and staypoints\n",
    "    print(\"starting merge\", stps.shape, trips.shape)\n",
    "    stps[\"type\"] = \"stp\"\n",
    "    trips[\"type\"] = \"trip\"\n",
    "    df_all = pd.merge(stps, trips, how=\"outer\")\n",
    "    print(\"finished merge\", df_all.shape)\n",
    "    print(\"*\"*50)\n",
    "\n",
    "    return df_all\n",
    "\n",
    "stps = get_stps()\n",
    "trips = get_trips()\n",
    "all_trace = _get_all_trace(stps, trips)\n",
    "\n",
    "print(len(stps['user_id'].unique()), len(trips['user_id'].unique()), len(all_trace['user_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the user filter\n",
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id   quality  days\n",
      "0       1617  0.992109   430\n",
      "1       1602  0.987011   434\n",
      "2       1721  0.986556   421\n",
      "3       1673  0.986205   415\n",
      "4       1716  0.985793   421\n",
      "..       ...       ...   ...\n",
      "111     1802  0.720105   406\n",
      "112     1628  0.717939   415\n",
      "113     1609  0.716239   421\n",
      "114     1601  0.716053   342\n",
      "115     1760  0.701097   415\n",
      "\n",
      "[116 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# get the total quality and tracked days\n",
    "total_quality = temporal_tracking_quality(all_trace, granularity=\"all\")\n",
    "total_quality['days'] = all_trace.groupby(\"user_id\").apply(lambda x: (x['finished_at'].max() - x['started_at'].min()).days).values\n",
    "\n",
    "total_quality.sort_values(by='quality', ascending=False, inplace=True)\n",
    "\n",
    "# select total quality and tracked days\n",
    "selected = total_quality.loc[(total_quality['days']>300) & (total_quality['quality']>0.7)].reset_index(drop=True)\n",
    "# save\n",
    "selected.to_csv(os.path.join(config[\"quality\"], \"SBB_user_filtered.csv\"), index=False)\n",
    "\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window based\n",
    "Ensure high tracking quality throughout the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id   quality\n",
      "0    1596.0  0.973634\n",
      "1    1597.0  0.966084\n",
      "2    1602.0  0.978700\n",
      "3    1605.0  0.922213\n",
      "4    1606.0  0.959640\n",
      "..      ...       ...\n",
      "88   1805.0  0.777991\n",
      "89   1810.0  0.872272\n",
      "90   1812.0  0.958226\n",
      "91   1848.0  0.954729\n",
      "92   1934.0  0.870983\n",
      "\n",
      "[93 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def filter_user(df):\n",
    "    consider = df.loc[df['quality']!=0]\n",
    "    if consider['quality'].min() > 0.6:\n",
    "        return df\n",
    "\n",
    "def getTrackingQuality(df, window_size):\n",
    "\n",
    "    weeks = (df['finished_at'].max() - df['started_at'].min()).days // 7\n",
    "    start_date = df['started_at'].min().date()\n",
    "\n",
    "    quality_list = []\n",
    "    # construct the sliding week gdf\n",
    "    for i in range(0, weeks-window_size):\n",
    "        curr_start = datetime.datetime.combine(start_date + datetime.timedelta(weeks=i), datetime.time())\n",
    "        curr_end  = datetime.datetime.combine(curr_start + datetime.timedelta(weeks=window_size), datetime.time())\n",
    "\n",
    "        # the total df for this time window\n",
    "        cAll_gdf = df.loc[(df['started_at'] >= curr_start) & (df['finished_at'] < curr_end)]\n",
    "        if cAll_gdf.shape[0] == 0:\n",
    "            continue\n",
    "        total_sec = (curr_end-curr_start).total_seconds()\n",
    "\n",
    "        quality_list.append([i, cAll_gdf['duration'].sum()/total_sec])\n",
    "    ret = pd.DataFrame(quality_list, columns=['timestep','quality'])\n",
    "    ret[\"user_id\"] = df[\"user_id\"].unique()[0]\n",
    "    return ret\n",
    "\n",
    "sliding = all_trace.groupby(\"user_id\").apply(getTrackingQuality, window_size=10).reset_index(drop=True)\n",
    "\n",
    "# use selected as a filter \n",
    "sliding = sliding.loc[sliding['user_id'].isin(selected['user_id'].unique())]\n",
    "\n",
    "\n",
    "slide_user = sliding.groupby(\"user_id\").apply(filter_user).reset_index(drop=True).dropna()\n",
    "slide_user = slide_user.groupby(\"user_id\", as_index=False)[\"quality\"].mean()\n",
    "\n",
    "# save\n",
    "slide_user.to_csv(os.path.join(config[\"quality\"], \"SBB_user_window_filtered.csv\"), index=False)\n",
    "\n",
    "print(slide_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
